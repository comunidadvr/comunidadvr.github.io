<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on VRChile</title><link>https://vrchile.github.io/post/</link><description>Recent content in Posts on VRChile</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 09 Jan 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://vrchile.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Clean White Theme for Hugo</title><link>https://vrchile.github.io/post/readme/</link><pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/post/readme/</guid><description>Clean White Theme for Hugo CleanWhite is a clean, elegant, but fully functional blog theme for Hugo. Here is a live demo site using this theme.
It is based on huxblog Jekyll Theme and Clean Blog Jekyll Theme.
These two upstream projects have done awesome jobs to create a blog theme, what I&amp;rsquo;m doing here is porting it to Hugo, of which I like the simplicity and the much faster compiling speed.</description></item><item><title>Istio v1aplha3 routing API介绍(译文）</title><link>https://vrchile.github.io/2018/06/04/introducing-the-istio-v1alpha3-routing-api/</link><pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/06/04/introducing-the-istio-v1alpha3-routing-api/</guid><description>&lt;p>到目前为止，Istio提供了一个简单的API来进行流量管理，该API包括了四种资源：RouteRule，DestinationPolicy，EgressRule和Ingress（直接使用了Kubernets的Ingress资源）。借助此API，用户可以轻松管理Istio服务网格中的流量。该API允许用户将请求路由到特定版本的服务，为弹性测试注入延迟和失败，添加超时和断路器等等，所有这些功能都不必更改应用程序本身的代码。&lt;/p></description></item><item><title>Istio 0.8 Release发布</title><link>https://vrchile.github.io/2018/06/02/istio08/</link><pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/06/02/istio08/</guid><description>&lt;blockquote>
&lt;p>在6月1日这一天的早上，Istio社区宣布发布0.8 Release，除了常规的故障修复和性能改进外，这个儿童节礼物里面还有什么值得期待内容呢？让我们来看一看：&lt;/p>
&lt;/blockquote></description></item><item><title>Everything about Setting Up My Ubuntu Desktop</title><link>https://vrchile.github.io/2018/05/24/set_up_my_ubuntu_desktop/</link><pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/24/set_up_my_ubuntu_desktop/</guid><description>Generate SSH Key Pair ssh-keygen -C &amp;#34;zhaohuabing@gmail.com&amp;#34; Shadowsocks Install shadowsokcs
sudo apt-get install python3-pip sudo pip3 install shadowsocks Create config at config/shadowsocks.json, with the following content:
{ &amp;#34;server&amp;#34;:&amp;#34;remote-shadowsocks-server-ip-addr&amp;#34;, &amp;#34;server_port&amp;#34;:443, &amp;#34;local_address&amp;#34;:&amp;#34;127.0.0.1&amp;#34;, &amp;#34;local_port&amp;#34;:1080, &amp;#34;password&amp;#34;:&amp;#34;your-passwd&amp;#34;, &amp;#34;timeout&amp;#34;:300, &amp;#34;method&amp;#34;:&amp;#34;aes-256-cfb&amp;#34;, &amp;#34;fast_open&amp;#34;:false, &amp;#34;workers&amp;#34;:1 } Start a local socks proxy
sudo sslocal -c config/shadowsocks.json -d start In case there is an openssl error, modify shadowsocks source file.
sudo vi /usr/local/lib/python3.6/dist-packages/shadowsocks/crypto/openssl.py :%s/cleanup/reset/gc Convert shadowsocks socks proxy to http proxy</description></item><item><title>微服务安全沉思录之三</title><link>https://vrchile.github.io/2018/05/23/external_system_auth/</link><pubDate>Wed, 23 May 2018 18:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/23/external_system_auth/</guid><description>外部系统访问控制 除用户访问和微服务之间的相互访问外，外部的第三方系统也可能需要访问系统内部的微服务。例如在上一篇博客的网上商店例子中，外部的推荐服务可能需要接入系统，以获取商店的商品目录信息。相对于内部服务之间的访问而言，外部系统的访问需要进行严格的安全控制。
使用账号进行控制 可以为外部系统创建一个用户账号，类似普通用户一样对外部系统的账号进行管理，并使用该账号对外部系统进行认证和权限控制。
采用这种方式的问题是难以处理用户相关的敏感数据。因为外部系统自身也是微服务系统中的一个用户账号，因此该外部系统只能访问该账号自身的数据和一些不敏感的公共数据，而不能访问和用户相关的数据。例如在网上商店的例子中，外部系统可以采用该方式访问商品目录信息，但不应允许访问用户历史购买记录，用户余额等信息。
API Token 是一个API Token（又称API Key）可以控制对用户敏感数据的访问。微服务应用提供一个API Token的生成界面，用户登录后可以生成自己的API Token，并在第三方应用使用该API Token访问微服务的API。在这种情况下，一般只允许第三方应用访问该Token所属用户自身的数据，而不能访问其他用户的敏感私有数据。
例如Github就提供了Personal API Token功能，用户可以在Github的开发者设置界面中创建Token，然后使用该Token来访问Github的API。在创建Token时，可以设置该Token可以访问用户的哪些数据，如查看Repo信息，删除Repo，查看用户信息，更新用户信息等。
使用API Token来访问Github API
curl -u zhaohuabing:fbdf8e8862252ed0f3ba9dba4e328c01ac93aeec https://api.github.com/user 不用试了,这不是我的真实API Token, just for demonstration :-)
使用API Token而不是直接使用用户名/密码来访问API的好处是降低了用户密码暴露的风险，并且可以随时收回Token的权限而不用修改密码。
由于API Token只能访问指定用户的数据，因此适合于用户自己开发一些脚本或小程序对应用中自己的数据进行操作。
OAuth 某些第三方应用需要访问不同用户的数据，或者对多个用户的数据进行整合处理，则可以考虑采用OAuth。采用OAuth，当第三方应用访问服务时，应用会提示用户授权第三方应用相应的访问权限，根据用户的授权操作结果生成用于访问的Token，以对第三方应用的操作请求进行访问控制。
同样以Github为例，一些第三方应用如Travis CI，GitBook等就是通过OAuth和Github进行集成的。 OAuth针对不同场景有不同的认证流程，一个典型的认证流程如下图所示：
用户向OAuth客户端程序发起一个请求，OAuth客户端程序在处理该请求时发现需要访问用户在资源服务器中的数据。 客户端程序将用户请求重定向到认证服务器，该请求中包含一个callback的URL。 认证服务器返回授权页面，要求用户对OAuth客户端的资源请求进行授权。 用户对该操作进行授权后，认证服务器将请求重定向到客户端程序的callback url，将授权码返回给客户端程序。 客户端程序将授权码发送给认证服务器，请求token。 认证服务器验证授权码后将token颁发给客户端程序。 客户端程序采用颁发的token访问资源，完成用户请求。 备注：
OAuth中按照功能区分了资源服务器和认证服务器这两个角色，在实现时这两个角色常常是同一个应用。将该流程图中的各个角色对应到Github的例子中，资源服务器和认证服务器都是Github，客户端程序是Travis CI或者GitBook，用户则是使用Travis CI或者GitBook的直接用户。
有人可能会疑惑在该流程中为何要使用一个授权码(Authorization Code)来申请Token，而不是由认证服务器直接返回Token给客户端。OAuth这样设计的原因是在重定向到客户端Callback URL的过程中会经过用户代理（浏览器），如果直接传递Token存在被窃取的风险。采用授权码的方式，申请Token时客户端直接和认证服务器进行交互，并且认证服务期在处理客户端的Token申请请求时还会对客户端进行身份认证，避免其他人伪造客户端身份来使用认证码申请Token。 下面是一个客户端程序采用Authorization Code来申请Token的示例，client_id和client_secret被用来验证客户端的身份。
POST /oauth/token HTTP/1.1 Host: authorization-server.com grant_type=authorization_code &amp;amp;code=xxxxxxxxxxx &amp;amp;redirect_uri=https://example-app.com/redirect &amp;amp;client_id=xxxxxxxxxx &amp;amp;client_secret=xxxxxxxxxx 另外在谈及OAuth时，我们需要注意微服务应用作为OAuth客户端和OAuth服务器的两种不同场景:
在实现微服务自身的用户认证时，也可以采用OAuth将微服务的用户认证委托给一个第三方的认证服务提供商，例如很多应用都将用户登录和微信或者QQ的OAuth服务进行了集成。
第三方应用接入和微服务自身用户认证采用OAuth的目的是不同的，前者是为了将微服务中用户的私有数据访问权限授权给第三方应用，微服务在OAuth架构中是认证和资源服务器的角色；而后者的目的是集成并利用知名认证提供服务商提供的OAuth认证服务，简化繁琐的注册操作，微服务在OAuth架构中是客户端的角色。
因此在我们需要区分这两种不同的场景，以免造成误解。
后记 前两篇文章在在公众号发布后，有朋友提到还要注意登录密码明文问题、防止重放攻击、防止时间差攻击、防止脱裤后的彩虹表攻击&amp;hellip;。的确，安全是一个庞大的话题，本系列文章只阐述了我关于微服务架构对应用安全带来的影响的一点小小思考。在产品开发和运维中，还需要对安全进行全方面的考虑，最好遵循一些业界的最佳实践，如采用完善的防火墙对外部流量进行隔离，采用加盐hash对用户密码进行存储，采用tls进行加密传输，对用户输入进行严格检查防止sql注入，采用经过验证的通用加密算法等等。</description></item><item><title>微服务安全沉思录之二</title><link>https://vrchile.github.io/2018/05/23/service_2_service_auth/</link><pubDate>Wed, 23 May 2018 15:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/23/service_2_service_auth/</guid><description>&lt;h2 id="服务间认证与鉴权">服务间认证与鉴权&lt;/h2>
&lt;p>除来自用户的访问请求以外，微服务应用中的各个微服务相互之间还有大量的访问，包括下述场景：&lt;/p>
&lt;ul>
&lt;li>用户间接触发的微服务之间的相互访问&lt;!-- raw HTML omitted -->
例如在一个网上商店应用中，用户访问购物车微服务进行结算时，购物车微服务可能需要访问用户评级微服务获取用户的会员级别，以得到用户可以享受购物折扣。&lt;/li>
&lt;li>非用户触发的微服务之间的相互访问&lt;!-- raw HTML omitted -->
例如数据同步或者后台定时任务导致的微服务之间的相互访问。&lt;/li>
&lt;/ul>
&lt;p>根据应用系统的数据敏感程度的不同，对于系统内微服务的相互访问可能有不同的安全要求。&lt;/p></description></item><item><title>微服务安全沉思录之一</title><link>https://vrchile.github.io/2018/05/22/user_authentication_authorization/</link><pubDate>Wed, 23 May 2018 10:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/22/user_authentication_authorization/</guid><description>这段时间对之前微服务安全相关的一些想法进行了进一步总结和归纳，理清了在之前文章里面没有想得太清楚的地方，例如服务间的认证与鉴权以及用户身份在服务调用链中的传递。
在这一系列文章里，我将尝试分为三个部分对微服务安全进行系统阐述：用户访问认证与鉴权，服务间认证与鉴权，外部系统访问控制。
目录 {:.no_toc}
目录 {:toc} 前言 微服务架构的引入为软件应用带来了诸多好处：包括小开发团队，缩短开发周期，语言选择灵活性，增强服务伸缩能力等。与此同时，也引入了分布式系统的诸多复杂问题。其中一个挑战就是如何在微服务架构中实现一个灵活，安全，高效的认证和鉴权方案。
相对于传统单体应用，微服务架构下的认证和鉴权涉及到场景更为复杂，涉及到用户访问微服务应用，第三方应用访问微服务应用，应用内多个微服务之间相互访问等多种场景，每种场景下的认证和鉴权方案都需要考虑到，以保证应用程序的安全性。本系列博文将就此问题进行一次比较完整的探讨。 用户认证和鉴权 用户身份认证 一个完整的微服务应用是由多个相互独立的微服务进程组成的，对每个微服务的访问都需要进行用户认证。如果将用户认证的工作放到每个微服务中，存在下面一些问题：
需要在各个微服务中重复实现这部分公共逻辑。虽然我们可以使用代码库复用部分代码，但这又会导致所有微服务对特定代码库及其版本存在依赖，影响微服务语言/框架选择的灵活性。 将认证和鉴权的公共逻辑放到微服务实现中违背了单一职责原理，开发人员应重点关注微服务自身的业务逻辑。 用户需要分别登录以访问系统中不同的服务。 由于在微服务架构中以API Gateway作为对外提供服务的入口，因此可以在API Gateway处提供统一的用户认证，用户只需要登录一次，就可以访问系统中所有微服务提供的服务。
用户状态保持 HTTP是一个无状态的协议，对服务器来说，用户的每次HTTP请求是相互独立的。互联网是一个巨大的分布式系统，HTTP协议作为互联网上的一个重要协议，在设计之初要考虑到大量应用访问的效率问题。无状态意味着服务端可以把客户端的请求根据需要发送到集群中的任何一个节点，HTTP的无状态设计对负载均衡有明显的好处，由于没有状态，用户请求可以被分发到任意一个服务器，应用也可以在靠近用户的网络边缘部署缓存服务器。对于不需要身份认证的服务，例如浏览新闻网页等，这是没有任何问题的。但HTTP成为企业应用的一个事实标准后，企业应用需要保存用户的登录状态和身份以进行更严格的权限控制。因此需要在HTTP协议基础上采用一种方式保存用户的登录状态，避免用户每发起一次请求都需要进行验证。
传统方式是在服务器端采用Cookie来保存用户状态，由于在服务器是有状态的，对服务器的水平扩展有影响。在微服务架构下建议采用Token来记录用户登录状态。
Token和Seesion主要的不同点是存储的地方不同。Session是集中存储在服务器中的；而Token是用户自己持有的，一般以cookie的形式存储在浏览器中。Token中保存了用户的身份信息，每次请求都会发送给服务器，服务器因此可以判断访问者的身份，并判断其对请求的资源有没有访问权限。
Token用于表明用户身份，因此需要对其内容进行加密，避免被请求方或者第三者篡改。JWT(Json Web Token)是一个定义Token格式的开放标准(RFC 7519),定义了Token的内容，加密方式，并提供了各种语言的lib。
JWT Token的结构非常简单，包括三部分：
Header 头部包含类型,为固定值JWT。然后是JWT使用的Hash算法。 { &amp;#34;alg&amp;#34;: &amp;#34;HS256&amp;#34;, &amp;#34;typ&amp;#34;: &amp;#34;JWT&amp;#34; } Payload 包含发布者，过期时间，用户名等标准信息，也可以添加用户角色，用户自定义的信息。 { &amp;#34;sub&amp;#34;: &amp;#34;1234567890&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;John Doe&amp;#34;, &amp;#34;admin&amp;#34;: true } Signature Token颁发方的签名，用于客户端验证Token颁发方的身份，也用于服务器防止Token被篡改。 签名算法 HMACSHA256( base64UrlEncode(header) + &amp;#34;.&amp;#34; + base64UrlEncode(payload), secret) 这三部分使用Base64编码后组合在一起，成为最终返回给客户端的Token串，每部分之间采用&amp;quot;.&amp;ldquo;分隔。下图是上面例子最终形成的Token 采用Token进行用户认证，服务器端不再保存用户状态，客户端每次请求时都需要将Token发送到服务器端进行身份验证。Token发送的方式rfc6750进行了规定，采用一个 Authorization: Bearer HHTP Header进行发送。
Authorization: Bearer mF_9.B5f-4.1JqM 采用Token方式进行用户认证的基本流程如下图所示：
用户输入用户名,密码等验证信息，向服务器发起登录请求 服务器端验证用户登录信息，生成JWT token 服务器端将Token返回给客户端，客户端保存在本地（一般以Cookie的方式保存） 客户端向服务器端发送访问请求，请求中携带之前颁发的Token 服务器端验证Token，确认用户的身份和对资源的访问权限，并进行相应的处理（拒绝或者允许访问） 实现单点登录 单点登录的理念很简单，即用户只需要登录应用一次，就可以访问应用中所有的微服务。API Gateway提供了客户端访问微服务应用的入口，Token实现了无状态的用户认证。结合这两种技术，可以为微服务应用实现一个单点登录方案。</description></item><item><title>Istio Sidecar自动注入原理</title><link>https://vrchile.github.io/2018/05/23/istio-auto-injection-with-webhook/</link><pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/23/istio-auto-injection-with-webhook/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;hr>
&lt;p>Kubernets 1.9版本引入了Admission Webhook(web 回调)扩展机制，通过Webhook,开发者可以非常灵活地对Kubernets API Server的功能进行扩展，在API Server创建资源时对资源进行验证或者修改。&lt;/p>
&lt;p>使用webhook的优势是不需要对API Server的源码进行修改和重新编译就可以扩展其功能。插入的逻辑实现为一个独立的web进程，通过参数方式传入到kubernets中，由kubernets在进行自身逻辑处理时对扩展逻辑进行回调。&lt;/p>
&lt;p>Istio 0.7版本就利用了Kubernets webhook实现了sidecar的自动注入。&lt;/p></description></item><item><title>川西秘境探险</title><link>https://vrchile.github.io/2018/05/01/may-day-jiulonghu/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/01/may-day-jiulonghu/</guid><description>&lt;h2 id="寻浮云牧场不遇">寻浮云牧场不遇&lt;/h2>
&lt;p>五一节前的一周内，几个朋友就纷纷坐不住了，一个二个不再安心上班，开始在微信群里讨论过节要到哪里耍。
大家思来想去，最后决定还是去理县方向。因为根据多年自驾的经验，只要出了汶川，沿途都是风景。&lt;/p></description></item><item><title>Helm介绍</title><link>https://vrchile.github.io/2018/04/16/using-helm-to-deploy-to-kubernetes/</link><pubDate>Mon, 16 Apr 2018 15:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/04/16/using-helm-to-deploy-to-kubernetes/</guid><description>前言 Helm是Kubernetes生态系统中的一个软件包管理工具。本文将介绍为何要使用Helm进行Kubernetes软件包管理，澄清Helm中使用到的相关概念，并通过一个具体的示例学习如何使用Helm打包，分发，安装，升级及回退Kubernetes应用。
Kubernetes应用部署的挑战 让我们首先来看看Kubernetes，kubernetes提供了基于容器的应用集群管理，为容器化应用提供了部署运行、资源调度、服务发现和动态伸缩等一系列完整功能。
kubernetes的核心设计理念是: 用户定义应用程序的规格，而kubernetes则负责按照定义的规则部署并运行应用程序，如果应用系统出现问题导致偏离了定义的规格，kubernetes负责对其进行自动修正。例如应用规格要求部署两个实例，其中一个实例异常终止了，kubernetes会检查到并重新启动一个新的实例。
用户通过使用kubernetes API对象来描述应用程序规格，包括Pod，Service，Volume，Namespace，ReplicaSet，Deployment，Job等等。一般这些对象需要写入一系列的yaml文件中，然后通过kubernetes命令行工具kubectl进行部署。
以下面的wordpress应用程序为例，涉及到多个kubernetes API对象，这些kubernetes API对象分散在多个yaml文件中。
图1： Wordpress应用程序中涉及到的kubernetes API对象 可以看到，在进行kubernetes软件部署时，我们面临下述问题：
如何管理，编辑和更新这些这些分散的kubernetes应用配置文件？ 如何把一套的相关配置文件作为一个应用进行管理？ 如何分发和重用kubernetes的应用配置？ Helm的引入很好地解决上面这些问题。
Helm是什么？ 很多人都使用过Ubuntu下的ap-get或者CentOS下的yum, 这两者都是Linux系统下的包管理工具。采用apt-get/yum,应用开发者可以管理应用包之间的依赖关系，发布应用；用户则可以以简单的方式查找、安装、升级、卸载应用程序。
我们可以将Helm看作Kubernetes下的apt-get/yum。Helm是Deis (https://deis.com/) 开发的一个用于kubernetes的包管理器。
对于应用发布者而言，可以通过Helm打包应用，管理应用依赖关系，管理应用版本并发布应用到软件仓库。
对于使用者而言，使用Helm后不用需要了解Kubernetes的Yaml语法并编写应用部署文件，可以通过Helm下载并在kubernetes上安装需要的应用。
除此以外，Helm还提供了kubernetes上的软件部署，删除，升级，回滚应用的强大功能。
Helm组件及相关术语 开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。
因此我们先了解一下Helm的这些相关概念和术语。
Helm
Kubernetes的应用打包工具，也是命令行工具的名称。
Tiller
Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。
Chart
Helm的打包格式，内部包含了一组相关的kubernetes资源。
Repoistory
Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。
Release
使用Helm install命令在Kubernetes集群中安装的Chart称为Release。
需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。
其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。
下面这张图描述了Helm的几个关键组件Helm（客户端），Tiller（服务器），Repository（Chart软件仓库），Chart（软件包）之前的关系。
图2： Helm软件架构 安装Helm 下面我们通过一个完整的示例来介绍Helm的相关概念，并学习如何使用Helm打包，分发，安装，升级及回退kubernetes应用。
可以参考Helm的帮助文档https://docs.helm.sh/using_helm/#installing-helm 安装Helm
采用二进制的方式安装Helm
下载 Helm https://github.com/kubernetes/helm/releases 解压 tar -zxvf helm-v2.0.0-linux-amd64.tgz 拷贝到bin目录 mv linux-amd64/helm /usr/local/bin/helm 然后使用下面的命令安装服务器端组件Tiller
Helm init 构建一个Helm chart 让我们在实践中来了解Helm。这里将使用一个Go测试小程序，让我们先为这个小程序创建一个Helm chart。</description></item><item><title>Service Mesh 和 API Gateway的关系探讨（译文）</title><link>https://vrchile.github.io/2018/04/11/service-mesh-vs-api-gateway/</link><pubDate>Wed, 11 Apr 2018 09:32:00 +0000</pubDate><guid>https://vrchile.github.io/2018/04/11/service-mesh-vs-api-gateway/</guid><description>Service Mesh vs API Gateway 在前一篇关于Service Mesh的文章中,我提到了几个关于Service Mesh和API Gateway之间关系的问题，在本篇文章中，我打算就Service Mesh和API Gateway的用途进行进一步讨论。
为了区分API Gateway和Service Mesh，让我们先分别看看两者各自的关键特征。
API Gateway: 将服务作为被管理的API向外部暴露 使用API Gateway的主要目的是将微服务作为被管理的API暴露（给外部系统）。因此，我们在API Gateway层开发的API或者边界服务对外提供了业务功能。
API/边界服务调用下游的组合或者原子微服务，通过组合/混装多个下游微服务的方式来提供业务逻辑。
在API/Edge服务调用下游服务时，需要采用一种可靠的通信方式，应用了断路器，超时，负载均衡/故障转移等可靠性模式。因此大部分的API Gateway解决方案都内置了这些特性。
API Gateway也内置了以下特性的支持，包括：服务发现，分析（可见性：性能指标，监控，分布式日志，分布式调用追踪）和安全。
API Gateway和API管理生态系统的其他组件的关系紧密，比如： API 市场/商店， API 发布门户。
Service Mesh：微服务的网络通信基础设施 现在我们来看看Service Mesh有哪些不同。
Service Mesh是一个网络通信基础设施， 可以用于将应用层的网络通信功能从你的服务代码中剥离出来。
采用Service Mesh， 你不用在服务代码中实现用于可靠通信的模式如断路，超时等，类似地，Service Mesh也提供了服务发现，服务可见性等其他功能。
API Gateway和Service Mesh实践 API Gateway和Service Mesh之间的主要不同点：API Gateway是暴露API/边界服务的关键组件，而Service Mesh则仅仅是一个服务间通信的基础设施，并不了解应用中的业务逻辑。
下图说明了API Gateway和Service Mesh的关系。如同前面所说，这两者之间也有一些重叠的部分（例如断路器等），但重要的是需要理解这两者是用于完全不同的用途。
图1： API Gateway和Service Mesh实践
如上图所示，Service Mesh作为Sidecar（边车）和服务一起部署，它是独立于服务的业务逻辑的。
另一方面，API Gateway 提供了所有的API服务（这些API服务有明确定义的业务功能），它是应用业务逻辑的一部分。API Gateway可以具有内建的服务间通信能力，但它也可以使用Service Mesh来调用下游服务（API Gateway-&amp;gt;Service Mesh-&amp;gt;Microservices）。
在API管理层次，你可以使用API Gateway内建的服务间通信能力；也可以通过Service Mesh来调用下游服务，以将应用网络通信功能从应用程序转移到Service Mesh中。</description></item><item><title>谈谈微服务架构中的基础设施：Service Mesh与Istio</title><link>https://vrchile.github.io/2018/03/29/what-is-service-mesh-and-istio/</link><pubDate>Thu, 29 Mar 2018 12:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/03/29/what-is-service-mesh-and-istio/</guid><description>&lt;h2 id="微服务架构的演进">微服务架构的演进&lt;/h2>
&lt;p>作为一种架构模式，微服务将复杂系统切分为数十乃至上百个小服务，每个服务负责实现一个独立的业务逻辑。这些小服务易于被小型的软件工程师团队所理解和修改，并带来了语言和框架选择灵活性，缩短应用开发上线时间，可根据不同的工作负载和资源要求对服务进行独立缩扩容等优势。&lt;/p>
&lt;p>另一方面，当应用被拆分为多个微服务进程后，进程内的方法调用变成了了进程间的远程调用。引入了对大量服务的连接、管理和监控的复杂性。&lt;/p></description></item><item><title>如何配置docker使用HTTP代理</title><link>https://vrchile.github.io/2018/03/13/use-docker-behind-http-proxy/</link><pubDate>Tue, 13 Mar 2018 18:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/03/13/use-docker-behind-http-proxy/</guid><description>&lt;h2 id="ubuntu">Ubuntu&lt;/h2>
&lt;h3 id="设置docker使用http-proxy">设置docker使用http proxy&lt;/h3>
&lt;pre tabindex="0">&lt;code>sudo /etc/default/docker
export http_proxy=&amp;#34;http://127.0.0.1:3128/&amp;#34;
export https_proxy=&amp;#34;http://127.0.0.1:3128/&amp;#34;
export HTTP_PROXY=&amp;#34;http://127.0.0.1:3128/&amp;#34;
export HTTPS_PROXY=&amp;#34;http://127.0.0.1:3128/&amp;#34;
&lt;/code>&lt;/pre></description></item><item><title>Vim Tips</title><link>https://vrchile.github.io/2018/02/09/vim-tips/</link><pubDate>Fri, 09 Feb 2018 11:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/02/09/vim-tips/</guid><description>&lt;h2 id="vim-graphical-cheat-sheet">vim graphical cheat sheet&lt;/h2>
&lt;p>
&lt;img src="//img/2018-02-09-vim-tips/vi-vim-cheat-sheet.svg" alt="">
&lt;/p></description></item><item><title>如何使用非root用户执行docker命令</title><link>https://vrchile.github.io/2018/02/09/docker-without-sudo/</link><pubDate>Fri, 09 Feb 2018 10:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/02/09/docker-without-sudo/</guid><description>Add the docker group if it doesn&amp;rsquo;t already exist: sudo groupadd docker
Add the connected user &amp;ldquo;$USER&amp;rdquo; to the docker group. Change the user name to match your preferred user if you do not want to use your current user: sudo gpasswd -a $USER docker
Either do a newgrp docker or log out/in to activate the changes to groups.</description></item><item><title>如何构建安全的微服务应用？</title><link>https://vrchile.github.io/2018/05/22/user_authentication_authorization/</link><pubDate>Sat, 03 Feb 2018 12:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/05/22/user_authentication_authorization/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>微服务架构的引入为软件应用带来了诸多好处：包括小开发团队，缩短开发周期，语言选择灵活性，增强服务伸缩能力等。与此同时，也引入了分布式系统的诸多复杂问题。其中一个挑战就是如何在微服务架构中实现一个灵活，安全，高效的认证和鉴权方案。本文将尝试就此问题进行一次比较完整的探讨。&lt;/p></description></item><item><title>Nginx开源Service Mesh组件Nginmesh安装指南</title><link>https://vrchile.github.io/2018/01/02/nginmesh-install/</link><pubDate>Tue, 02 Jan 2018 12:00:00 +0000</pubDate><guid>https://vrchile.github.io/2018/01/02/nginmesh-install/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Nginmesh是NGINX的Service Mesh开源项目，用于Istio服务网格平台中的数据面代理。它旨在提供七层负载均衡和服务路由功能，与Istio集成作为sidecar部署，并将以“标准，可靠和安全的方式”使得服务间通信更容易。Nginmesh在今年底已经连续发布了0.2和0.3版本，提供了服务发现，请求转发，路由规则，性能指标收集等功能。&lt;/p></description></item><item><title>如何从外部访问Kubernetes集群中的应用？</title><link>https://vrchile.github.io/2017/11/28/access-application-from-outside/</link><pubDate>Tue, 28 Nov 2017 12:00:00 +0000</pubDate><guid>https://vrchile.github.io/2017/11/28/access-application-from-outside/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>我们知道，kubernetes的Cluster Network属于私有网络，只能在cluster Network内部才能访问部署的应用，那如何才能将Kubernetes集群中的应用暴露到外部网络，为外部用户提供服务呢？本文探讨了从外部网络访问kubernetes cluster中应用的几种实现方式。&lt;/p></description></item><item><title>采用Istio实现灰度发布(金丝雀发布)</title><link>https://vrchile.github.io/2017/11/08/istio-canary-release/</link><pubDate>Wed, 08 Nov 2017 15:00:00 +0000</pubDate><guid>https://vrchile.github.io/2017/11/08/istio-canary-release/</guid><description>灰度发布（又名金丝雀发布）介绍 当应用上线以后，运维面临的一大挑战是如何能够在不影响已上线业务的情况下进行升级。做过产品的同学都清楚，不管在发布前做过多么完备的自动化和人工测试，在发布后都会出现或多或少的故障。根据墨菲定律，可能会出错的版本发布一定会出错。
&amp;ldquo;ANYTHING THAN CAN GO WRONG WILL GO WRONG&amp;rdquo; &amp;ndash;MURPHY&amp;rsquo;S LAW
因此我们不能寄希望于在线下测试时发现所有潜在故障。在无法百分百避免版本升级故障的情况下，需要通过一种方式进行可控的版本发布，把故障影响控制在可以接受的范围内，并可以快速回退。
可以通过灰度发布（又名金丝雀发布）来实现业务从老版本到新版本的平滑过渡，并避免升级过程中出现的问题对用户造成的影响。
“金丝雀发布”的来源于矿工们用金丝雀对矿井进行空气测试的做法。以前矿工挖煤的时候，矿工下矿井前会先把金丝雀放进去，或者挖煤的时候一直带着金丝雀。金丝雀对甲烷和一氧化碳浓度比较敏感，会先报警。所以大家都用“金丝雀”来搞最先的测试。
下图中，左下方的少部分用户就被当作“金丝雀”来用于测试新上线的1.1版本。如果新版本出现问题，“金丝雀”们会报警，但不会影响其他用户业务的正常运行。 灰度发布（金丝雀发布）的流程如下：
准备和生产环境隔离的“金丝雀”服务器。 将新版本的服务部署到“金丝雀”服务器上。 对“金丝雀”服务器上的服务进行自动化和人工测试。 测试通过后，将“金丝雀”服务器连接到生产环境，将少量生产流量导入到“金丝雀”服务器中。 如果在线测试出现问题，则通过把生产流量从“金丝雀”服务器中重新路由到老版本的服务的方式进行回退，修复问题后重新进行发布。 如果在线测试顺利，则逐渐把生产流量按一定策略逐渐导入到新版本服务器中。 待新版本服务稳定运行后，删除老版本服务。 Istio实现灰度发布(金丝雀发布)的原理 从上面的流程可以看到，如果要实现一套灰度发布的流程，需要应用程序和运维流程对该发布过程进行支持，工作量和难度的挑战是非常大的。虽然面对的问题类似，但每个企业或组织一般采用不同的私有化实现方案来进行灰度发布,为解决该问题导致研发和运维花费了大量的成本。
Istio通过高度的抽象和良好的设计采用一致的方式解决了该问题，采用sidecar对应用流量进行了转发，通过Pilot下发路由规则，可以在不修改应用程序的前提下实现应用的灰度发布。
备注：采用kubernetes的滚动升级(rolling update)功能也可以实现不中断业务的应用升级,但滚动升级是通过逐渐使用新版本的服务来替换老版本服务的方式对应用进行升级，在滚动升级不能对应用的流量分发进行控制，因此无法采用受控地把生产流量逐渐导流到新版本服务中，也就无法控制服务升级对用户造成的影响。
采用Istio后，可以通过定制路由规则将特定的流量（如指定特征的用户）导入新版本服务中，在生产环境下进行测试，同时通过渐进受控地导入生产流量，可以最小化升级中出现的故障对用户的影响。并且在同时存在新老版本服务时，还可根据应用压力对不同版本的服务进行独立的缩扩容，非常灵活。采用Istio进行灰度发布的流程如下图所示： 操作步骤 下面采用Istion自带的BookinfoInfo示例程序来试验灰度发布的流程。
测试环境安装 首先参考手把手教你从零搭建Istio及Bookinfo示例程序安装Kubernetes及Istio控制面。
因为本试验并不需要安装全部3个版本的reviews服务，因此如果已经安装了该应用，先采用下面的命令卸载。
istio-0.2.10/samples/bookinfo/kube/cleanup.sh 部署V1版本的服务 首先只部署V1版本的Bookinfo应用程序。由于示例中的yaml文件中包含了3个版本的reviews服务，我们先将V2和V3版本的Deployment从yaml文件istio-0.2.10/samples/bookinfo/kube/bookinfo.yaml中删除。
从Bookinfo.yaml中删除这部分内容:
apiVersion: extensions/v1beta1 kind: Deployment metadata: name: reviews-v2 spec: replicas: 1 template: metadata: labels: app: reviews version: v2 spec: containers: - name: reviews image: istio/examples-bookinfo-reviews-v2:0.2.3 imagePullPolicy: IfNotPresent ports: - containerPort: 9080 --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: reviews-v3 spec: replicas: 1 template: metadata: labels: app: reviews version: v3 spec: containers: - name: reviews image: istio/examples-bookinfo-reviews-v3:0.</description></item><item><title>使用Istio实现应用流量转移</title><link>https://vrchile.github.io/2017/11/07/istio-traffic-shifting/</link><pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2017/11/07/istio-traffic-shifting/</guid><description>&lt;p>关于Istio的更多内容请参考&lt;a href="http://istio.doczh.cn/">istio中文文档&lt;/a>。&lt;/p>
&lt;p>原文参见&lt;a href="https://istio.io/docs/tasks/traffic-management/traffic-shifting.html">Traffic Shifting&lt;/a>。&lt;/p>
&lt;p>本任务将演示如何将应用流量逐渐从旧版本的服务迁移到新版本。通过Istio，可以使用一系列不同权重的规则（10%，20%，··· 100%）将流量平缓地从旧版本服务迁移到新版本服务。&lt;/p></description></item><item><title>Istio及Bookinfo示例程序安装试用笔记</title><link>https://vrchile.github.io/2017/11/04/istio-install_and_example/</link><pubDate>Sat, 04 Nov 2017 12:00:00 +0000</pubDate><guid>https://vrchile.github.io/2017/11/04/istio-install_and_example/</guid><description>&lt;h2 id="服务网格简介">服务网格简介&lt;/h2>
&lt;p>&lt;strong>服务网格&lt;/strong>（Service Mesh）是为解决微服务的通信和治理而出现的一种&lt;strong>架构模式&lt;/strong>。&lt;/p>
&lt;p>服务网格将服务间通讯以及与此相关的管理控制功能从业务程序中下移到一个基础设施层，从而彻底隔离了业务逻辑和服务通讯两个关注点。采用服务网格后，应用开发者只需要关注并实现应用业务逻辑。服务之间的通信，包括服务发现，通讯的可靠性，通讯的安全性，服务路由等由服务网格层进行处理，并对应用程序透明。&lt;/p></description></item><item><title>Welcome to Zhaohuabing Blog</title><link>https://vrchile.github.io/2017/11/03/hello-world/</link><pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate><guid>https://vrchile.github.io/2017/11/03/hello-world/</guid><description> “Yeah It&amp;rsquo;s on. ”
Hello World!</description></item></channel></rss>